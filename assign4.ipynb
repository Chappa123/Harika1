{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import*\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "X,y = fetch_openml('mnist_784', version = 1, return_X_y=True)\n",
    "X = X / 255\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 70000)\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(10, 70000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "digits = 10\n",
    "examples = y.shape[0]\n",
    "\n",
    "y = y.reshape(1, examples)\n",
    "print(y.shape)\n",
    "Y_new = np.eye(digits)[y.astype('int32')]\n",
    "\n",
    "Y_new = Y_new.T.reshape(digits, examples)\n",
    "print(Y_new)\n",
    "print(Y_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(10, 60000)\n",
      "(784, 10000)\n",
      "(10, 10000)\n",
      "[50529     9  4182 ... 30216 52094 59716]\n",
      "(784, 60000)\n",
      "(10, 60000)\n"
     ]
    }
   ],
   "source": [
    "m = 60000\n",
    "m_test = X.shape[0] - m\n",
    "\n",
    "X_train, X_test = X[:m].T, X[m:].T\n",
    "Y_train, Y_test = Y_new[:,:m], Y_new[:,m:]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "shuffle_index = np.random.permutation(m)\n",
    "print(shuffle_index)\n",
    "X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAABitJREFUeJzt3c+LzXscx/FzbhoZSiykyVKilJCN\nlSaynWQ/LFhobG0mydqGmgX+AVJ+ZWehWLFGmWykUUTTFM1Oczc2994+78M5zplrXo/H9nW/3/NN\n99lZfOac011ZWekAef5a7QcAVof4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IdS6Eb+ePyeE4ev+zH/k\nnR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CiR9C\niR9CiR9CiR9CjfqruyPduHGj3BcXF4f22ps2bSr38+fPD+21+X/zzg+hxA+hxA+hxA+hxA+hxA+h\nxA+huisrI/3V7D/2J7pPnz7d3O7du1deu7y8XO7fv3/v65l+Rrdb/1pzr78DOH78eLnfuXPnl5+J\nofMT3UCb+CGU+CGU+CGU+CGU+CGU+CGUc/4fJiYmyv3Tp0/Nrde/4dTUVLlv3ry53Ifp+fPn5T4/\nP1/u27dvL/e3b982t40bN5bX0jfn/ECb+CGU+CGU+CGU+CGU+CGU+CGUc/4fen3ufefOnc1tenq6\nvPbChQvlPjY2Vu7DVP39QqfT6Vy6dKnce/0mwalTp5rbzMxMee3BgwfLnSbn/ECb+CGU+CGU+CGU\n+CGU+CGUo74frly5Uu4bNmxobr2OrP5kCwsL5X7r1q1yn52dbW6Tk5PltXfv3i13HwluctQHtIkf\nQokfQokfQokfQokfQokfQjnnZ6iqryX/+vVree3jx4/L/ejRo309UwDn/ECb+CGU+CGU+CGU+CGU\n+CGU+CGUc36G6ty5c83t+vXr5bXHjh0r9wcPHpR79R0Ma5xzfqBN/BBK/BBK/BBK/BBK/BBK/BDK\nOT9D9ebNm+Z2+PDh8tqlpaVyf/HiRbkfOnSo3Ncw5/xAm/ghlPghlPghlPghlPghlPgh1LrVfgDW\ntt27dze38fHx8tpe5/wMxjs/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/hBI/\nhPKRXoZqbm6uuX348GGET8K/eeeHUOKHUOKHUOKHUOKHUOKHUOKHUM75GarLly83t273p35JmiHx\nzg+hxA+hxA+hxA+hxA+hxA+hxA+hnPMzkJcvX5b7t2/f+r737Oxsue/bt6/ve+OdH2KJH0KJH0KJ\nH0KJH0KJH0KJH0J1V1ZWRvl6I30xBvfq1atyn5ycLPcvX740t6mpqfLa27dvl/vY2Fi5B/upL0rw\nzg+hxA+hxA+hxA+hxA+hxA+hfKR3jet1VPfu3btyP3v2bLl//vy53Kuv515eXi6vffbsWbn3cuDA\ngea2devWge69Fnjnh1Dih1Dih1Dih1Dih1Dih1Dih1A+0vs/8PDhw3Kfm5vr+96vX78u948fP/Z9\n706n0+n1/89q/gz3/v37m1uvc/6TJ0/2fe9Op9PZsWNHuU9MTJT7gHykF2gTP4QSP4QSP4QSP4QS\nP4QSP4Ryzj8Cjx49Kvfp6elyX1pa+p2P80u2bdtW7lu2bCn3Qc75e/2898LCQt/3HrYjR46U+5Mn\nT4b58s75gTbxQyjxQyjxQyjxQyjxQyjxQyjn/COwZ8+ecp+fnx/Rk/xXr3P4a9eulfvMzMzvfJx/\neP/+fbk/ffq073v3+r2Bq1evlvv69evL/f79++W+d+/ech+Qc36gTfwQSvwQSvwQSvwQSvwQylHf\nCAz7qG98fLy59fqK6osXL5b7mTNn+nomVpWjPqBN/BBK/BBK/BBK/BBK/BBK/BDKOf8I3Lx5s9wX\nFxcHuv+JEyea265duwa6N38k5/xAm/ghlPghlPghlPghlPghlPghlHN+WHuc8wNt4odQ4odQ4odQ\n4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ\n4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ4odQ60b8et0Rvx7Q4J0f\nQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokfQokf\nQokfQokfQokfQv0NBvHwfm+MBtkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c28e77780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 12\n",
    "import matplotlib.pyplot as plt\n",
    "print(X_train.shape)\n",
    "plt.imshow(X_train[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "Y_train[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_multiclass_loss(Y, Y_hat):\n",
    "\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    m = Y.shape[1]\n",
    "    L = -(1/m) * L_sum\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(10, 60000)\n",
      "(64, 784)\n",
      "Epoch 0 cost:  7.981436511162305\n",
      "Epoch 1 cost:  5.670801126113979\n",
      "Epoch 2 cost:  4.163419544741337\n",
      "Epoch 3 cost:  3.4796412636782588\n",
      "Epoch 4 cost:  2.8487704423410416\n",
      "Epoch 5 cost:  2.5847945818119054\n",
      "Epoch 6 cost:  2.4429224422224824\n",
      "Epoch 7 cost:  2.314334976136332\n",
      "Epoch 8 cost:  2.2093168438756017\n",
      "Epoch 9 cost:  2.1179240642958987\n",
      "Epoch 10 cost:  2.0366976732161923\n",
      "Epoch 11 cost:  1.9654968971433133\n",
      "Epoch 12 cost:  1.9006592923446652\n",
      "Epoch 13 cost:  1.842672469655808\n",
      "Epoch 14 cost:  1.7894928648529564\n",
      "Epoch 15 cost:  1.7411255813446642\n",
      "Epoch 16 cost:  1.6964972836301404\n",
      "Epoch 17 cost:  1.6554524882113593\n",
      "Epoch 18 cost:  1.617275390745682\n",
      "Epoch 19 cost:  1.5819217886577306\n",
      "Epoch 20 cost:  1.5487501594703492\n",
      "Epoch 21 cost:  1.517897543762684\n",
      "Epoch 22 cost:  1.488719004833011\n",
      "Epoch 23 cost:  1.4614896710408862\n",
      "Epoch 24 cost:  1.435575618901585\n",
      "Epoch 25 cost:  1.4113138988703982\n",
      "Epoch 26 cost:  1.3881210978235512\n",
      "Epoch 27 cost:  1.3663296060028651\n",
      "Epoch 28 cost:  1.345438643782133\n",
      "Epoch 29 cost:  1.3257337497488624\n",
      "Epoch 30 cost:  1.3068112559373195\n",
      "Epoch 31 cost:  1.2888916182398982\n",
      "Epoch 32 cost:  1.2716665941734226\n",
      "Epoch 33 cost:  1.2552907292194462\n",
      "Epoch 34 cost:  1.2395391089381302\n",
      "Epoch 35 cost:  1.2245095011692293\n",
      "Epoch 36 cost:  1.210043651970443\n",
      "Epoch 37 cost:  1.1961956667122087\n",
      "Epoch 38 cost:  1.1828569929137644\n",
      "Epoch 39 cost:  1.1700512536432868\n",
      "Epoch 40 cost:  1.1577048261544611\n",
      "Epoch 41 cost:  1.1458220070169047\n",
      "Epoch 42 cost:  1.1343525395598737\n",
      "Epoch 43 cost:  1.1232897694242472\n",
      "Epoch 44 cost:  1.1125984934110011\n",
      "Epoch 45 cost:  1.1022667798393309\n",
      "Epoch 46 cost:  1.0922689225285755\n",
      "Epoch 47 cost:  1.0825911839168976\n",
      "Epoch 48 cost:  1.0732138618268985\n",
      "Epoch 49 cost:  1.064123305933426\n",
      "Epoch 50 cost:  1.0553037213882357\n",
      "Epoch 51 cost:  1.0467424277093718\n",
      "Epoch 52 cost:  1.0384263078785352\n",
      "Epoch 53 cost:  1.0303439554809282\n",
      "Epoch 54 cost:  1.0224842041334332\n",
      "Epoch 55 cost:  1.0148369340935988\n",
      "Epoch 56 cost:  1.0073924802127048\n",
      "Epoch 57 cost:  1.0001418987957487\n",
      "Epoch 58 cost:  0.993076728478387\n",
      "Epoch 59 cost:  0.9861890551745349\n",
      "Epoch 60 cost:  0.9794714098893466\n",
      "Epoch 61 cost:  0.9729167651359308\n",
      "Epoch 62 cost:  0.9665184853607484\n",
      "Epoch 63 cost:  0.9602703041311685\n",
      "Epoch 64 cost:  0.9541662953505206\n",
      "Epoch 65 cost:  0.9482008480848994\n",
      "Epoch 66 cost:  0.942368646673861\n",
      "Epoch 67 cost:  0.9366646482412218\n",
      "Epoch 68 cost:  0.9310840671685108\n",
      "Epoch 69 cost:  0.9256223562600286\n",
      "Epoch 70 cost:  0.9202751937633271\n",
      "Epoch 71 cost:  0.9150384678763729\n",
      "Epoch 72 cost:  0.9099082655258098\n",
      "Epoch 73 cost:  0.9048808595990911\n",
      "Epoch 74 cost:  0.8999526990930937\n",
      "Epoch 75 cost:  0.8951203984758095\n",
      "Epoch 76 cost:  0.8903807289807549\n",
      "Epoch 77 cost:  0.885730609615546\n",
      "Epoch 78 cost:  0.8811670994459817\n",
      "Epoch 79 cost:  0.8766873898873551\n",
      "Epoch 80 cost:  0.8722887978530793\n",
      "Epoch 81 cost:  0.8679687590619205\n",
      "Epoch 82 cost:  0.8637248219430321\n",
      "Epoch 83 cost:  0.859554641764468\n",
      "Epoch 84 cost:  0.8554559751991649\n",
      "Epoch 85 cost:  0.8514266751312429\n",
      "Epoch 86 cost:  0.8474646857992221\n",
      "Epoch 87 cost:  0.8435680381725404\n",
      "Epoch 88 cost:  0.8397348455998526\n",
      "Epoch 89 cost:  0.8359632996736733\n",
      "Epoch 90 cost:  0.8322516663227484\n",
      "Epoch 91 cost:  0.8285982821012011\n",
      "Epoch 92 cost:  0.8250015506741666\n",
      "Epoch 93 cost:  0.8214599394814206\n",
      "Epoch 94 cost:  0.8179719765743299\n",
      "Epoch 95 cost:  0.8145362476140311\n",
      "Epoch 96 cost:  0.8111513930249601\n",
      "Epoch 97 cost:  0.8078161052950182\n",
      "Epoch 98 cost:  0.8045291264164557\n",
      "Epoch 99 cost:  0.8012892454605975\n",
      "(64, 60000)\n",
      "(64, 64)\n",
      "(64, 1)\n",
      "(64, 60000)\n",
      "(64, 60000)\n",
      "(64, 784)\n",
      "(64, 1)\n",
      "Final cost: 0.8012892454605975\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):                                        \n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "n_x = X_train.shape[0]\n",
    "n_h1 = 64\n",
    "n_h2 = 64\n",
    "learning_rate = 0.9\n",
    "\n",
    "W1 = np.random.randn(n_h1, n_x)\n",
    "b1 = np.zeros((n_h1, 1))\n",
    "W2 = np.random.randn(n_h2, n_h1)\n",
    "b2 = np.zeros((n_h2, 1))\n",
    "W3 = np.random.randn(digits, n_h2)\n",
    "b3 = np.zeros((digits, 1))\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(W1.shape)\n",
    "for i in range(100):\n",
    "\n",
    "    Z1 = np.matmul(W1,X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.matmul(W2,A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    Z3 = np.matmul(W3,A2) + b3\n",
    "    A3 = np.exp(Z3) / np.sum(np.exp(Z3), axis=0)\n",
    "\n",
    "    cost = compute_multiclass_loss(Y, A3)\n",
    "\n",
    "    dZ3 = A3-Y\n",
    "    dW3 = (1./m) * np.matmul(dZ3, A2.T)\n",
    "    db3 = (1./m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "    \n",
    "    dA2 = np.matmul(W3.T, dZ3)\n",
    "    dZ2 = dA2 * sigmoid(Z2) * (1 - sigmoid(Z2))\n",
    "    dW2 = (1./m) * np.matmul(dZ2, A1.T)\n",
    "    db2 = (1./m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = np.matmul(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
    "    dW1 = (1./m) * np.matmul(dZ1, X.T)\n",
    "    db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    W3 = W3 - learning_rate * dW3\n",
    "    b3 = b3 - learning_rate * db3\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "\n",
    "    print(\"Epoch\", i, \"cost: \", cost)\n",
    "print(dZ2.shape)\n",
    "print(dW2.shape)\n",
    "print(db2.shape)\n",
    "print(dA1.shape)\n",
    "print(dZ1.shape)\n",
    "print(dW1.shape)\n",
    "print(db1.shape)\n",
    "\n",
    "\n",
    "print(\"Final cost:\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 6 1 ... 7 5 6]\n",
      "[7 2 1 ... 4 5 6]\n",
      "[[ 873    0   13   19    6   34   28    8   20   10]\n",
      " [   0 1074   20    9    6   12    6   27   21   10]\n",
      " [  19   15  769   68   25   20   64   33   43   12]\n",
      " [  14    9   66  739    7   90    8   10   82   13]\n",
      " [   5    1   17    3  704   44   22   25   39  125]\n",
      " [  41    8   17   81   10  519   23   13   62   28]\n",
      " [  18    1   53   10   39   26  787    4   37   10]\n",
      " [   4    4   23   21   14   37    1  796   35   91]\n",
      " [   4   21   44   44   15   73   14   26  550   33]\n",
      " [   2    2   10   16  156   37    5   86   85  677]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88      1011\n",
      "           1       0.95      0.91      0.93      1185\n",
      "           2       0.75      0.72      0.73      1068\n",
      "           3       0.73      0.71      0.72      1038\n",
      "           4       0.72      0.71      0.72       985\n",
      "           5       0.58      0.65      0.61       802\n",
      "           6       0.82      0.80      0.81       985\n",
      "           7       0.77      0.78      0.78      1026\n",
      "           8       0.56      0.67      0.61       824\n",
      "           9       0.67      0.63      0.65      1076\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.74      0.74      0.74     10000\n",
      "weighted avg       0.75      0.75      0.75     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import*\n",
    "Z1 = np.matmul(W1, X_test) + b1\n",
    "A1 = sigmoid(Z1)\n",
    "Z2 = np.matmul(W2, A1) + b2\n",
    "A2 = sigmoid(Z2)\n",
    "Z3 = np.matmul(W3, A2) + b3\n",
    "A3 = np.exp(Z3) / np.sum(np.exp(Z3), axis=0)\n",
    "\n",
    "#print(A2)\n",
    "#print(Y_test)\n",
    "predictions = np.argmax(A3, axis=0)\n",
    "labels = np.argmax(Y_test, axis=0)\n",
    "print(predictions)\n",
    "print(labels)\n",
    "print(confusion_matrix(predictions, labels))\n",
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
